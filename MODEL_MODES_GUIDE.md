# vLLM ì„œë²„ ëª¨ë¸ ëª¨ë“œ ê°€ì´ë“œ

## ğŸ“‹ ëª¨ë¸ ëª¨ë“œ ë¹„êµ

| í•­ëª© | FP16 ëª¨ë“œ | 4bit ëª¨ë“œ |
|------|-----------|-----------|
| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | ~60GB | ~30GB |
| **ì¶”ë¡  ì†ë„** | ë¹ ë¦„ | ì¤‘ê°„ (5-15% ëŠë¦¼) |
| **ë™ì‹œ ì²˜ë¦¬** | 24 ì‹œí€€ìŠ¤ | 48 ì‹œí€€ìŠ¤ |
| **ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸** | 8192 í† í° | 12288 í† í° |
| **Fine-tuning** | âœ… ê°€ëŠ¥ | âœ… QLoRA ê°€ëŠ¥ |
| **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±** | ë³´í†µ | ë†’ìŒ |
| **ì²˜ë¦¬ëŸ‰** | ë†’ìŒ | ë§¤ìš° ë†’ìŒ |

## ğŸš€ ì‚¬ìš©ë²•

### 1. FP16 ëª¨ë“œ (ê³ ì„±ëŠ¥)
```bash
# Foreground ì‹¤í–‰
./start_vllm_with_options.sh start fp16

# Background ì‹¤í–‰  
./start_vllm_with_options.sh start-bg fp16
```

### 2. 4bit ëª¨ë“œ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
```bash
# Foreground ì‹¤í–‰
./start_vllm_with_options.sh start 4bit

# Background ì‹¤í–‰
./start_vllm_with_options.sh start-bg 4bit
```

### 3. LoRA ì–´ëŒ‘í„°ì™€ í•¨ê»˜ ì‹¤í–‰
```bash
# FP16 + LoRA ì–´ëŒ‘í„°
./start_vllm_with_options.sh start fp16 --with-lora

# 4bit + LoRA ì–´ëŒ‘í„°
./start_vllm_with_options.sh start-bg 4bit --with-lora
```

### 4. í˜„ì¬ ì„¤ì • í™•ì¸
```bash
./start_vllm_with_options.sh status
```

## ğŸ”§ ì¶”ë¡  ìš”ì²­ ì‹œ LoRA ì–´ëŒ‘í„° ì„ íƒ

### ìš”ì²­ë³„ LoRA ì–´ëŒ‘í„° ì§€ì •
```bash
# ì±„íŒ… ìš”ì²­ with specific LoRA
curl -X POST "http://localhost:8001/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ì•ˆë…•í•˜ì„¸ìš”!",
    "lora_adapter": "vision_v1",
    "max_tokens": 512
  }'

# ì´ë¯¸ì§€ ë¶„ì„ with specific LoRA  
curl -X POST "http://localhost:8001/vision" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
    "image_data": "data:image/jpeg;base64,/9j/4AAQ...",
    "lora_adapter": "document_v2"
  }'
```

### LoRA ì–´ëŒ‘í„° ê´€ë¦¬ API
```bash
# ë“±ë¡ëœ LoRA ì–´ëŒ‘í„° ëª©ë¡
curl http://localhost:8001/lora/adapters

# ê¸°ë³¸ LoRA ì–´ëŒ‘í„° ì„¤ì •
curl -X POST "http://localhost:8001/lora/set-default?adapter_name=vision_v1"

# í˜„ì¬ ëª¨ë¸ ì •ë³´ í™•ì¸
curl http://localhost:8001/models
```

## ğŸ¯ LoRA ì–´ëŒ‘í„° ê´€ë¦¬

### LoRA ì–´ëŒ‘í„° ìë™ ìŠ¤ìº”
```bash
cd vllm_server/
python lora_manager.py scan
```

### LoRA ì–´ëŒ‘í„° ìˆ˜ë™ ì¶”ê°€
```bash
python lora_manager.py add --name my_adapter --path /path/to/adapter --default
```

### LoRA ì–´ëŒ‘í„° ëª©ë¡ í™•ì¸
```bash
python lora_manager.py list
```

### ê¸°ë³¸ LoRA ì–´ëŒ‘í„° ì„¤ì •
```bash
python lora_manager.py set-default --name my_adapter
```

### .env íŒŒì¼ ìë™ ì—…ë°ì´íŠ¸
```bash
python lora_manager.py update-env
```

## ğŸ¯ ê¶Œì¥ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### FP16 ëª¨ë“œ ê¶Œì¥:
- **ì‹¤ì‹œê°„ ì±„íŒ…**: ë¹ ë¥¸ ì‘ë‹µì´ ì¤‘ìš”í•œ ê²½ìš°
- **ë‹¨ì¼ ì‚¬ìš©ì**: ë™ì‹œ ì²˜ë¦¬ê°€ ë§ì§€ ì•Šì€ ê²½ìš°  
- **ê³ í’ˆì§ˆ ì¶”ë¡ **: ìµœê³  í’ˆì§ˆì´ í•„ìš”í•œ ê²½ìš°

### 4bit ëª¨ë“œ ê¶Œì¥:
- **ë‹¤ì¤‘ ì‚¬ìš©ì**: ë™ì‹œ ì ‘ì†ìê°€ ë§ì€ ê²½ìš°
- **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ ì‘ì—… ì²˜ë¦¬ì‹œ
- **ë©”ëª¨ë¦¬ ì œì•½**: GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•œ ê²½ìš°
- **ë¹„ìš© ì ˆì•½**: ì¸í”„ë¼ ë¹„ìš© ì ˆê°ì´ ì¤‘ìš”í•œ ê²½ìš°

## ğŸ”§ Fine-tuning ê°€ì´ë“œ

### FP16 ëª¨ë¸ Fine-tuning
```bash
cd training/
python train_vision_lora.py --config config_vision.json
```

### 4bit ëª¨ë¸ Fine-tuning (QLoRA)
```bash
cd training/
# config_vision.jsonì—ì„œ qlora ì„¤ì • í™œì„±í™”ë¨
python train_vision_lora.py --config config_vision.json --use_4bit
```

## ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### GPU ë©”ëª¨ë¦¬ í™•ì¸
```bash
nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv,noheader,nounits
```

### vLLM ì„œë²„ ìƒíƒœ í™•ì¸
```bash
curl http://localhost:8001/health
```

### ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸
```bash
cd vllm_server/
python test_vllm_performance.sh
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

### ëª¨ë“œ ì „í™˜ì‹œ:
1. ê¸°ì¡´ ì„œë²„ ì™„ì „ ì¢…ë£Œ í•„ìš”
2. GPU ë©”ëª¨ë¦¬ ì™„ì „ í•´ì œ í™•ì¸
3. ìƒˆë¡œìš´ ëª¨ë“œë¡œ ì¬ì‹œì‘

### ë©”ëª¨ë¦¬ ê´€ë¦¬:
- **FP16**: GPU ë©”ëª¨ë¦¬ 92% ì‚¬ìš©
- **4bit**: GPU ë©”ëª¨ë¦¬ 85% ì‚¬ìš© (ì•ˆì •ì„± ê³ ë ¤)

### í˜¸í™˜ì„±:
- vLLM ìµœì‹  ë²„ì „ ê¶Œì¥
- CUDA 11.8+ í•„ìš”
- PyTorch 2.0+ í•„ìš”

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜:
```bash
# GPU ë©”ëª¨ë¦¬ ê°•ì œ í•´ì œ
python -c "import torch; torch.cuda.empty_cache()"

# í”„ë¡œì„¸ìŠ¤ í™•ì¸ ë° ì¢…ë£Œ
ps aux | grep vllm
kill -9 <PID>
```

### ì–‘ìí™” ì˜¤ë¥˜:
```bash
# bitsandbytes ì¬ì„¤ì¹˜
pip uninstall bitsandbytes -y
pip install bitsandbytes
```

### ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜:
```bash
# ëª¨ë¸ ìºì‹œ ì‚­ì œ
rm -rf ~/.cache/huggingface/transformers/
```
